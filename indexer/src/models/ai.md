I have this schema in my database using drizzle. export const entities = pgTable("entities", { id: text().primaryKey(), }) export const values = pgTable("values", { id: text().primaryKey(), entityId: text().notNull(), spaceId: text().notNull(), value: text().notNull(), }) export const relations = pgTable("relations", { id: text().primaryKey(), entityId: text().notNull(), typeId: text().notNull(), fromEntityId: text().notNull(), fromSpaceId: text(), fromVersionId: text(), toEntityId: text().notNull(), toSpaceId: text(), toVersionId: text(), position: text(), spaceId: text().notNull(), verified: boolean(), }) I also have these messages in a protobuf. These messages represent events with changes users can make to tables in postgres conforming to the above schema. syntax = "proto3"; package ipfsv2; message Edit { bytes id = 1; string name = 2; repeated Op ops = 3; repeated bytes authors = 4; optional bytes language = 5; } message ImportEdit { bytes id = 1; string name = 2; repeated Op ops = 3; repeated bytes authors = 4; bytes created_by = 5; string created_at = 6; bytes block_hash = 7; string block_number = 8; bytes transaction_hash = 9; } message Import { // these strings are IPFS cids representing the import edit message repeated string edits = 1; } message IpfsFile { string version = 1; oneof payload { Edit add_edit = 2; Import import_space = 3; bytes archive_space = 4; } } message Op { oneof payload { Entity update_entity = 1; bytes delete_entity = 2; Relation create_relation = 3; RelationUpdate update_relation = 4; bytes delete_relation = 5; UnsetEntityValues unset_entity_values = 6; UnsetRelationFields unset_relation_fields = 7; } } message UnsetEntityValues { bytes id = 1; repeated bytes properties = 2; } message Relation { bytes id = 1; bytes type = 2; bytes from_entity = 3; optional bytes from_space = 4; optional bytes from_version = 6; bytes to_entity = 7; optional bytes to_space = 8; optional bytes to_version = 10; bytes entity = 11; optional string position = 12; optional bool verified = 13; } message RelationUpdate { bytes id = 1; optional bytes from_space = 2; optional bytes from_version = 3; optional bytes to_space = 4; optional bytes to_version = 5; optional string position = 6; optional bool verified = 7; } message UnsetRelationFields { bytes id = 1; optional bool from_space = 2; optional bool from_version = 3; optional bool to_space = 4; optional bool to_version = 5; optional bool position = 6; optional bool verified = 7; } message Entity { bytes id = 1; repeated Value values = 2; } message Value { bytes property_id = 1; string value = 2; }

These events can be batched into an Edit, containing an ordered set of the Op.payload type. Currently we attempt to batch all of the events in the edit into a vector that maps to the schema, then we batch write/update/delete from the DB for each of the tables. In order to batch we have to do pre-compute the final state of the events in order to write the correct data since the data is ordered, but can come in any order. What's a simple way of writing this data to the db while preserving the order of events, but while pre-computing the final state of these entries before writing them to the database? Additionally, we want to optimize for parallelization by being able pre-compute the entities, values, and relations separately.

Write an implementation using Rust. Make sure that we aggregate pre-computed data for values, relations, and entities separately. If an entity is deleted then updated then we should write the updated data.
